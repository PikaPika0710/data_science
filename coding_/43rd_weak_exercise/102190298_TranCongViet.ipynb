{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dữ liệu trống hoàn toàn ngẫu nhiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cac hanh khach ko co du lieu ve dia diem len tau\n",
    "df[df['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dữ liệu trống không ngẫu nhiên => Có mối quan hệ với các dữ liệu khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hành khách không có dữ liệu về chỗ ngồi = 1, ngược lại bằng 0\n",
    "df['Cabin_null'] = np.where(df['Cabin'].isnull(), 1, 0)\n",
    "df['Cabin_null']\n",
    "# Tìm phần trăm hành khách không có dữ liệu về chỗ ngồi\n",
    "df['Cabin_null'].mean()\n",
    "# Tìm phần trăm hành khách không có dữ liệu về chỗ ngồi, phần trăm theo tình trạng sống chết\n",
    "df.groupby(['Survived'])['Cabin_null'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Những người không sống sót bị trống dữ liệu về chỗ ngồi nhiều hơn người sống sót"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các kỹ thuật xử lý dữ liệu trống\n",
    "\n",
    "- Giá trị trung bình/trung vị/giá trị xuất hiện nhiều nhất (Mean/\n",
    "Median/Mode imputation)\n",
    "- Giá trị được lấy ngẫu nhiên từ dữ liệu (Random sample imputation)\n",
    "- Giá trị tại đuôi của phân bố dữ liệu (End of distribution imputation)\n",
    "- Giá trị bất kỳ (Arbitrary Value Imputation)\n",
    "- Tạo đặc trưng mới (Create a new feature) đánh dấu các quan sát chứa\n",
    "dữ liệu trống\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('titanic.csv',usecols=['Age','Fare','Survived', 'Sex'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phan tram du lieu trong cua moi cot\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Cột 'Age' có 19% dữ liệu vị trống, còn 2 cột 'Survived' và 'Fare' thì không bị trống dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_density_function(old_data, new_data):\n",
    "    # ve ham mat do xac suat cua cot Age truoc va sau khi dien du lieu trong\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    old_data.plot(kind='kde', color='blue')\n",
    "    new_data.plot(kind='kde', color='red')\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(lines, labels, loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_before_and_after(method, before, after):    \n",
    "# in ra do lech chuan truoc va sau khi dien du lieu trong\n",
    "    print('***' + method + '***')\n",
    "    print(before.std())\n",
    "    print(after.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 kỹ thuật xử lý dữ liệu trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean \n",
    "mean = df['Age'].mean()\n",
    "df['Age_mean'] = df['Age'].fillna(mean)\n",
    "get_std_before_and_after('Mean', df['Age'], df['Age_mean'])\n",
    "probability_density_function(df['Age'], df['Age_mean'])\n",
    "\n",
    "# Median\n",
    "median = df['Age'].median()\n",
    "df['Age_median'] = df['Age'].fillna(median)\n",
    "get_std_before_and_after('Median', df['Age'], df['Age_median'])\n",
    "probability_density_function(df['Age'], df['Age_median'])\n",
    "\n",
    "# Mode \n",
    "mode = df['Age'].mode().values[0]\n",
    "df['Age_mode'] = df['Age'].fillna(mode)\n",
    "get_std_before_and_after('Mode', df['Age'], df['Age_mode'])\n",
    "probability_density_function(df['Age'], df['Age_mode'])\n",
    "\n",
    "# Random value\n",
    "## Lấy ngẫu nhiên từ cột Age n giá trị khác NaN, kết quả sẽ lặp lại sau mỗi lần thực hiện lệnh\n",
    "random_samples = df['Age'].dropna().sample(n = df['Age'].isnull().sum(), random_state = 0)\n",
    "## Chỉ số của khách hàng bị trống trong dữ liệu Age\n",
    "random_samples.index = df['Age'][df['Age'].isnull()].index\n",
    "## Thay thế dữ liệu trống bằng các giá trị ngẫu nhiên của cột\n",
    "df['Age_random'] = df['Age']\n",
    "## Lấy ra những vị trí Age = Nah của cột Age_random và gán với những giá trị ngẫu nhiên tìm được\n",
    "df.loc[df['Age'].isnull(), 'Age_random']=random_samples\n",
    "get_std_before_and_after('Random value', df['Age'], df['Age_random'])\n",
    "probability_density_function(df['Age'], df['Age_random'])\n",
    "\n",
    "# End of distribution \n",
    "## Gia tri o duoi cua phan bo (bien Age theo phan bo chuan)\n",
    "age_end = df['Age'].mean() + 3 * df['Age'].std()\n",
    "df['Age_end_dist'] = df['Age'].fillna(age_end)\n",
    "get_std_before_and_after('End of dist', df['Age'], df['Age_end_dist'])\n",
    "probability_density_function(df['Age'], df['Age_end_dist'])\n",
    "\n",
    "\n",
    "# Fix Value\n",
    "df['Age_fix_value'] = df['Age'].fillna(30) \n",
    "get_std_before_and_after('Fix value',df['Age'], df['Age_fix_value'])\n",
    "probability_density_function(df['Age'], df['Age_fix_value']) \n",
    "\n",
    "# New feature\n",
    "## Thay thế dữ liệu trống bằng 1 trong các kỹ thuật đã trình bày đồng thời tạo thêm biến để đánh dấu quan sát có dữ liệu trống\n",
    "df['Age_NAN'] = np.where(df['Age'].isnull(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram của biến Age sau khi thay Nah bằng End_of_dist\n",
    "df['Age_end_dist'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram của biến Age sau khi thay Nah bằng Median\n",
    "df['Age_mean'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu ngoại lệ (Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'].describe()\n",
    "df['Fare'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()\n",
    "df['Age'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu cột 'Fare' có dạng phân bố lệch (skewed) nên ta có: \n",
    "* ==> + Biên trên = 3rd Quantile + 3*IQR\n",
    "* ==> + Biên dưới =  1st Quantile - 3*IQR\n",
    "\n",
    "* IQR: Interquantile range\n",
    "    * 3rd Quantile = Percentile 75\n",
    "    * 1st Quantile = Percentile 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = df['Fare'].quantile(0.75) - df['Fare'].quantile(0.25)\n",
    "print(IQR)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_boundary = df['Fare'].quantile(0.75) + 3 * IQR\n",
    "lower_boundary = df['Fare'].quantile(0.25) - 3 * IQR\n",
    "print(upper_boundary)\n",
    "print(lower_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cột Age phân bố chuẩn nên sử dụng công thức tìm cận trên cận dưới như sau:\n",
    "- Biên trên = GTTB + 3*Độ lệch chuẩn \n",
    "- Biên dưới = GTTB - 3*Độ lệch chuẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppper_boundary = df['Age_mean'].mean() + 3 * df['Age_mean'].std()\n",
    "lower_boundary = df['Age_mean'].mean() - 3 * df['Age_mean'].std()\n",
    "print(lower_boundary), print(uppper_boundary), print(df['Age_mean'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data_non_pr = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các giá trị biên trên và biên dưới của dữ liệu\n",
    "# Thay thế giá trị ngoại lệ bằng 1 trong 2 giá trị trên\n",
    "data.loc[data['Age'] >= 68, 'Age'] = 68\n",
    "data.loc[data['Fare'] >= 100, 'Fare'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân bố tuổi sau khi thay thế các giá trị > biên trên bằng 68\n",
    "figure = data['Age'].hist(bins=50)\n",
    "figure.set_title('Age')\n",
    "figure.set_xlabel('Age')\n",
    "figure.set_ylabel('Nber of passengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân bố giá vé sau khi gán các giá trị > biên trên với 100\n",
    "figure = data.Fare.hist(bins=50)\n",
    "figure.set_title('Fare')\n",
    "figure.set_xlabel('Fare')\n",
    "figure.set_ylabel('Nber of passengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "handle_accuracy = []\n",
    "non_handle_accuracy = []\n",
    "for random_state in range(10):\n",
    "    # Training data\n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(\n",
    "        data[['Age_mean', 'Fare']], data['Survived'], test_size=0.3, random_state = random_state)\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(\n",
    "        data_non_pr[['Age_mean', 'Fare']], data_non_pr['Survived'], test_size=0.3, random_state = random_state)\n",
    "    # Fit the model according to the given training data.\n",
    "    classifier.fit(x1_train, y1_train)\n",
    "    # Predicting\n",
    "    y1_predict = classifier.predict(x1_test)\n",
    "    classifier.fit(x2_train, y2_train)\n",
    "    y2_predict = classifier.predict(x2_test)\n",
    "    handle_accuracy.append(accuracy_score(y1_test, y1_predict))\n",
    "    non_handle_accuracy.append(accuracy_score(y2_test, y2_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root means score 0.43688076788680386\n",
      "Variance score: 0.17\n",
      "Result : 0.1690897787773159\n",
      "     True Labels  Predicted Labels\n",
      "712            1          0.450097\n",
      "713            0          0.296749\n",
      "714            0          0.222255\n",
      "715            0          0.327487\n",
      "716            1          0.751173\n",
      "..           ...               ...\n",
      "886            0          0.323963\n",
      "887            1          0.448732\n",
      "888            0          0.369672\n",
      "889            1          0.420254\n",
      "890            0          0.275141\n",
      "\n",
      "[179 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "train,test,y_train,y_test=train_test_split(data[['Age_mean', 'Fare', 'Sex']], data['Survived'], test_size=0.2,shuffle=False)\n",
    "model = LinearRegression()\n",
    "model.fit(train, y_train)\n",
    "\n",
    "# predicting the  test set results  \n",
    "y_pred = model.predict(test)\n",
    "print('Root means score', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"Result :\",model.score(test, y_test))\n",
    "d1 = {'True Labels': y_test, 'Predicted Labels': y_pred}\n",
    "SK = pd.DataFrame(data = d1)\n",
    "print(SK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6977611940298507, 0.6231343283582089, 0.6865671641791045, 0.6231343283582089, 0.667910447761194, 0.6940298507462687, 0.7126865671641791, 0.6604477611940298, 0.667910447761194, 0.6380597014925373]\n",
      "[0.6865671641791045, 0.6194029850746269, 0.6567164179104478, 0.6417910447761194, 0.6753731343283582, 0.6455223880597015, 0.6865671641791045, 0.6305970149253731, 0.6567164179104478, 0.6305970149253731]\n"
     ]
    }
   ],
   "source": [
    "print(handle_accuracy)\n",
    "print(non_handle_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Handle exception): 0.6671641791044777\n",
      "Accuracy (Non handle exception): 0.6529850746268656\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (Handle exception): {}\".format(sum(handle_accuracy)/len(handle_accuracy)))\n",
    "print(\"Accuracy (Non handle exception): {}\".format(sum(non_handle_accuracy)/len(non_handle_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hóa dữ liệu\n",
    "* Data Standardization\n",
    "1. Chuẩn hoá theo z-score\n",
    "2. Chuẩn hoá Min-Max\n",
    "3. Chuẩn hoá mạnh với ngoại lệ (robust to outliers)\n",
    "4. Các kỹ thuật biến đổi dữ liệu khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm đặc trưng sex để cải thiện độ chính xác\n",
    "data['Sex'] = np.where(data['Sex']=='female', 0, 1)\n",
    "data_non_pr['Sex'] =  np.where(data_non_pr['Sex']=='female', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa Min-Max\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Chuẩn hóa theo z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Chuẩn hóa mạnh với ngoại lệ\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=40)\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_handle_ex = []\n",
    "scaled_non_handle_ex = []\n",
    "for random_state in range(10):\n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(\n",
    "        data[['Age_mean', 'Fare', 'Sex']], data['Survived'], test_size=0.3, random_state = random_state)\n",
    "\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(\n",
    "        data_non_pr[['Age_mean', 'Fare', 'Sex']], data_non_pr['Survived'], test_size=0.3, random_state = random_state)\n",
    "    \n",
    "    # chuẩn hóa trước khi fit model\n",
    "    x1_train = scaler.fit_transform(x1_train)\n",
    "    x1_test = scaler.fit_transform(x1_test)\n",
    "\n",
    "    x2_train = scaler.fit_transform(x2_train)\n",
    "    x2_test = scaler.fit_transform(x2_test)\n",
    "    \n",
    "    classifier.fit(x1_train, y1_train)\n",
    "    y1_predict = classifier.predict(x1_test)\n",
    "\n",
    "    classifier.fit(x2_train, y2_train)\n",
    "    y2_predict = classifier.predict(x2_test)\n",
    "\n",
    "    scaled_handle_ex.append(accuracy_score(y1_test, y1_predict))\n",
    "    scaled_non_handle_ex.append(accuracy_score(y2_test, y2_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy (Handle exception) After Normalize: {}\".format(sum(scaled_handle_ex)/len(scaled_handle_ex)))\n",
    "print(\"Accuracy (Non handle exception) After Normalize: {}\".format(sum(scaled_non_handle_ex)/len(scaled_non_handle_ex)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Cải thiện được 0.02 khi sử dụng phương pháp chuẩn hóa min-max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [[ 1, 2, 3], # 2 samples, 3 features\n",
    "[11, 12, 13]]\n",
    "y = [0, 1] # class labels of each sample\n",
    "clf.fit(X, y) # model fiGng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X) # predict classe labels of the training data\n",
    "clf.predict([[4, 5, 6], [14, 15, 16]]) # predict classe labels of the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = [[0, 15],\n",
    "[1, -10]]\n",
    "# scale data according to computed scaling values\n",
    "StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "result = cross_validate(lr, X, y) # defaults to 5-fold CV\n",
    "result['test_score'] # r_squared score is high because dataset is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "'max_depth': randint(5, 10)}\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "param_distributions=param_distributions,\n",
    "n_iter=5,\n",
    "random_state=0)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_ # Parameter setting that gave the best results on the hold out data\n",
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "StandardScaler(),\n",
    "LogisticRegression()\n",
    ")\n",
    "# load the iris dataset and split it into train and test sets\n",
    "X = data[['Age_mean', 'Fare']]\n",
    "y = data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "# we can now use it like any other estimator\n",
    "accuracy_score(y_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, y.shape\n",
    "# X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation: The following procedure is followed for each of the k “folds”:\n",
    "A model is trained using k - 1 of the folds as training data;\n",
    "\n",
    "The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K fold cross validation is used for the situation like: test and train is not similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "X = data[['Age_mean', 'Fare', 'Sex']]\n",
    "y = data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9,  shuffle=True, stratify=y)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=9, shuffle=True)\n",
    "\n",
    "kfold_acc = 0.\n",
    "for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "    clf = DecisionTreeClassifier(random_state=9, max_depth=3).fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "    y_pred = clf.predict(X_train.iloc[valid_idx])\n",
    "    acc = np.mean(y_pred == y_train.iloc[valid_idx])*100\n",
    "    kfold_acc += acc\n",
    "kfold_acc /= 10\n",
    "    \n",
    "clf = DecisionTreeClassifier(random_state=9, max_depth=3).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "test_acc = np.mean(y_pred == y_test)*100\n",
    "    \n",
    "print('Kfold Accuracy: %.2f%%' % kfold_acc)\n",
    "print('Test Accuracy: %.2f%%' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "X = data[['Age_mean', 'Fare', 'Sex']]\n",
    "y = data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5), 'max_depth': randint(5, 10)}\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),param_distributions=param_distributions,\n",
    "n_iter=5,\n",
    "random_state=0)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_ # Parameter setting that gave the best results on the hold out data\n",
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4d2420c1c86c857840e9cd37780cab37d65462fab81e90d4a4f57a598e20a77"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
